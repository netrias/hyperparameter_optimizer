{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a string pathway to a pip requirements.txt file or a conda environment.yml file. \n",
    "# You can remove this variable or leave it blank to have nb2app attempt to determine the dependencies automatically.\n",
    "# Examples:\n",
    "# requirements_file = 'requirements.txt'\n",
    "# requirements_file = 'my/path/environment.yml'\n",
    "requirements_file: str = '/Users/christopherpuglisi/Netrias/Projects/hyperparameter_optimizer/src/environment.yml'\n",
    "# Input string pathways to any files that the notebook will need to function when it is\n",
    "# containerized. \n",
    "# You can delete/leave this empty if there are no external files to include. \n",
    "# Example:\n",
    "# my_resource_files ['/absolute/path/encoders/my_encoder.h5', '/absolute/path/decoders/my_decoder.h5']\n",
    "resource_files: list = [\n",
    "]\n",
    "from pathlib import Path\n",
    "data_path: Path = Path('/Users/christopherpuglisi/Netrias/Projects/hyperparameter_optimizer/tests/cares_subset_aethr_features_overlapped_01312025.pkl')\n",
    "objective: str = 'Threat Detection Prediction'\n",
    "serialized_loss_name: str = 'binary_cross_entropy_loss.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the Python path to include the 'src' directory\n",
    "import sys\n",
    "import os\n",
    "import ast\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "src_path = os.path.abspath('../src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "from models.knn_models import KNNClassifierModel\n",
    "from optimizers.grid_search import GridSearchOptimizer\n",
    "from loss_functions.factory import LossFunctionFactory\n",
    "from models.bayesian_models import GaussianNBModel\n",
    "from optimizers.random_search import RandomSearchOptimizer\n",
    "from models.ensemble_models import RandomForestModel\n",
    "from models.linear_models import LogisticRegression\n",
    "from models.ensemble_models import RandomForestModel, GradientBoostingModel\n",
    "from models.bayesian_models import GaussianNBModel, BernoulliNBModel\n",
    "from models.knn_models import KNNClassifierModel\n",
    "from models.svm_models import SVCModel\n",
    "from models.bayesian_models import BayesianRidgeModel\n",
    "from models.linear_models import LogisticModel, RidgeModel, LassoModel\n",
    "from models.knn_models import KNNRegressorModel\n",
    "from models.svm_models import SVRModel\n",
    "from models.clustering_models import KMeansModel, DBSCANModel, AgglomerativeClusteringModel, SpectralClusteringModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if objective == 'Threat Detection Prediction':\n",
    "    loss_type_input: str = 'binary_cross_entropy'\n",
    "elif objective == 'Threat Severity Prediction':\n",
    "    loss_type_input: str = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Loss Function Parameters:\n",
      "{\n",
      "    \"weight_fp\": 1,\n",
      "    \"weight_fn\": 1,\n",
      "    \"threshold\": 0.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create a custom Binary Cross-Entropy Loss function\n",
    "weight_fp = 1\n",
    "weight_fn = 1\n",
    "threshold = 0.5\n",
    "\n",
    "loss_fn = LossFunctionFactory.create_loss_function(\n",
    "    loss_type=loss_type_input,\n",
    "    weight_fp= weight_fp,   # Penalize false positives more\n",
    "    weight_fn=weight_fn,   # Penalize false negatives even more\n",
    "    threshold=threshold   # Set prediction threshold to 0.6\n",
    ")\n",
    "\n",
    "# Display the loss function parameters\n",
    "print(\"Custom Loss Function Parameters:\")\n",
    "print(json.dumps(loss_fn.parameters, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X = data.iloc[:,3:].fillna(0)\n",
    "y = data['Threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A1A5D9', 'A6NDG6', 'O00233', 'O00299', 'O00391', 'O00410', 'O00442',\n",
       "       'O00560', 'O00592', 'O00743',\n",
       "       ...\n",
       "       'Q15717', 'Q4V328', 'Q8N392', 'Q96CX2', 'Q96JP5', 'Q9BW30', 'Q9ULH7',\n",
       "       'Q9Y4E1', 'Q9Y6H1', 'Q5T1J5'],\n",
       "      dtype='object', length=561)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 258\n",
      "Validation samples: 65\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_model(models_dict):\n",
    "    best_model_key = max(models_dict, key=lambda k: models_dict[k]['best_score'])\n",
    "    return best_model_key, models_dict[best_model_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_experiment(objective,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         X_val,\n",
    "                         y_val,\n",
    "                         loss_fn=None):\n",
    "    \"\"\"\n",
    "    Orchestrates model building and hyperparameter optimization\n",
    "    based on the provided objective_type (Classification, Regression, Unsupervised)\n",
    "    and model_type. Returns a dict of { 'model': ..., 'best_params': ..., etc. }.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------- CLASSIFICATION -------------------\n",
    "    if objective == 'Threat Detection Prediction':\n",
    "        results_dict = {}\n",
    "        # ---- Random Forest (Grid Search) ----\n",
    "        \n",
    "        rf_model = RandomForestModel(loss_function=loss_fn)\n",
    "        hyperparam_grid = {\n",
    "            'n_estimators': [100, 250, 500],\n",
    "            'max_depth': [None, 10, 25, 50],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "\n",
    "        rf_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=rf_model,\n",
    "            param_grid=hyperparam_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        # Unpack 3 values so we can use the fitted best_estimator\n",
    "        best_params, best_score, best_estimator = rf_grid_optimizer.optimize(X_train, y_train)\n",
    "        \n",
    "        # Evaluate using the fitted best_estimator\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['RandomForestClassifier'] = {\n",
    "            'model': best_estimator,     # store the fitted model\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "            # If your RandomSearchOptimizer now also returns 3 values:\n",
    "            # best_params, best_score, best_estimator = ...\n",
    "            # otherwise, ensure it sets gnb_model to the fitted params.\n",
    "        gnb_model = GaussianNBModel(loss_function=loss_fn)\n",
    "        gnb_param_distributions = {\n",
    "            'var_smoothing': np.logspace(0, -9, num=100)\n",
    "        }\n",
    "\n",
    "        gnb_random_optimizer = RandomSearchOptimizer(\n",
    "            model_instance=gnb_model,\n",
    "            param_distributions=gnb_param_distributions,\n",
    "            loss_function=loss_fn,\n",
    "            n_iter=20,\n",
    "            scoring='accuracy',\n",
    "            random_state=42\n",
    "        )\n",
    "        # Adjust if your RandomSearchOptimizer also returns best_score, best_estimator\n",
    "        best_params, best_score, best_estimator = gnb_random_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['GaussianNBClassifier'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        \n",
    "        bnb_model = BernoulliNBModel(loss_function=loss_fn)\n",
    "        bnb_param_grid = {\n",
    "            'alpha': [0.1, 1.0, 10.0],\n",
    "            'binarize': [0.0, 0.5, 1.0],\n",
    "            'fit_prior': [True, False]\n",
    "        }\n",
    "\n",
    "        bnb_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=bnb_model,\n",
    "            param_grid=bnb_param_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        best_params, best_score, best_estimator = bnb_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['BernoulliNBClassifier'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        \n",
    "        gb_model = GradientBoostingModel(loss_function=loss_fn)\n",
    "        gb_param_grid = {\n",
    "            'n_estimators': [50, 100],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 5]\n",
    "        }\n",
    "\n",
    "        gb_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=gb_model,\n",
    "            param_grid=gb_param_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        best_params, best_score, best_estimator = gb_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['GradientBoostingModel'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        knn_clf_model = KNNClassifierModel(loss_function=loss_fn)\n",
    "        knn_param_grid = {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
    "        }\n",
    "\n",
    "        knn_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=knn_clf_model,\n",
    "            param_grid=knn_param_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        best_params, best_score, best_estimator = knn_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['KNNClassifier'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "            }\n",
    "        \n",
    "        logistic_clf_model = LogisticModel(loss_function=loss_fn)\n",
    "\n",
    "        logistic_param_grid = {\n",
    "            'C': [0.1, 1.0, 10.0],  # Regularization strength\n",
    "            'penalty': ['l1', 'l2'],  # Regularization type\n",
    "            'solver': ['liblinear', 'saga']  # Solvers that support both l1 and l2\n",
    "        }\n",
    "\n",
    "        logistic_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=logistic_clf_model,\n",
    "            param_grid=logistic_param_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "\n",
    "        best_params, best_score, best_estimator = logistic_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['LogisticClassifier'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        #svc_model = SVCModel(loss_function=loss_fn)\n",
    "        #svc_param_grid = {\n",
    "        #    'C': [0.1, 1.0, 10.0],\n",
    "        #    'kernel': ['linear', 'rbf'],\n",
    "        #    'gamma': ['scale', 'auto']\n",
    "        #}\n",
    "\n",
    "        #svc_grid_optimizer = GridSearchOptimizer(\n",
    "        #    model_instance=svc_model,\n",
    "        #    param_grid=svc_param_grid,\n",
    "        #    loss_function=loss_fn,\n",
    "        #    cv=5,\n",
    "        #    scoring='accuracy'\n",
    "        #)\n",
    "        \n",
    "        #best_params, best_score, best_estimator = svc_grid_optimizer.optimize(X_train, y_train)\n",
    "        \n",
    "        #val_score = best_estimator.score(X_val, y_val)\n",
    "        #results_dict['SVClassifier'] = {\n",
    "        #    'model': best_estimator,\n",
    "        #    'best_params': best_params,\n",
    "        #    'best_score': best_score,\n",
    "        #    'validation_score': val_score\n",
    "        #}\n",
    "\n",
    "        top_model_key, top_model_value = get_top_model(results_dict)\n",
    "        top_model = top_model_value['model']\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_filename = f\"best_model_{top_model_key}_{timestamp}.pkl\"\n",
    "        print(model_filename)\n",
    "        # Save the model using pickle\n",
    "        with open(model_filename, 'wb') as f:\n",
    "            pickle.dump(top_model, f)\n",
    "\n",
    "        print(f\"Top model {top_model_key} saved as {model_filename}\")\n",
    "\n",
    "        return top_model_key, top_model_value, results_dict\n",
    "\n",
    "    # ------------------- REGRESSION -------------------\n",
    "    elif objective == 'Threat Severity Prediction':\n",
    "        results_dict = {}\n",
    "        lr_model = LogisticModel(loss_function=loss_fn)\n",
    "        hyperparam_grid = [\n",
    "            {\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'C': [0.01, 0.1, 1.0, 10],\n",
    "                'max_iter': [2500, 5000, 10000]\n",
    "            },\n",
    "            {\n",
    "                'penalty': [None],\n",
    "                'max_iter': [1000, 10000]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        lr_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=lr_model,\n",
    "            param_grid=hyperparam_grid,\n",
    "            loss_function=None,\n",
    "            cv=5,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        best_params, best_score, best_estimator = lr_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['LogisticRegression'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        br_model = BayesianRidgeModel(loss_function=loss_fn)\n",
    "        br_param_grid = {\n",
    "            'max_iter': [100, 300],\n",
    "            'alpha_1': [1e-6, 1e-5],\n",
    "            'alpha_2': [1e-6, 1e-5],\n",
    "        }\n",
    "\n",
    "        br_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=br_model,\n",
    "            param_grid=br_param_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='r2'\n",
    "        )\n",
    "        best_params, best_score, best_estimator = br_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['BayesianRidgeRegression'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        ridge_model = RidgeModel(loss_function=loss_fn)\n",
    "        ridge_param_grid = {\n",
    "            'alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "\n",
    "        ridge_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=ridge_model,\n",
    "            param_grid=ridge_param_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='r2'\n",
    "        )\n",
    "        best_params, best_score, best_estimator = ridge_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['RidgeRegression'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        lasso_model = LassoModel(loss_function=loss_fn)\n",
    "        lasso_param_grid = {\n",
    "            'alpha': [0.01, 0.1, 1.0, 10.0]\n",
    "        }\n",
    "\n",
    "        lasso_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=lasso_model,\n",
    "            param_grid=lasso_param_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='r2'\n",
    "        )\n",
    "        best_params, best_score, best_estimator = lasso_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['LassoRegression'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        knn_reg_model = KNNRegressorModel(loss_function=loss_fn)\n",
    "        knn_param_distributions = {\n",
    "            'n_neighbors': [2, 3, 5, 7, 10],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
    "        }\n",
    "\n",
    "        # If your random search returns 3 values, do the same here.\n",
    "        knn_random_optimizer = RandomSearchOptimizer(\n",
    "            model_instance=knn_reg_model,\n",
    "            param_distributions=knn_param_distributions,\n",
    "            loss_function=loss_fn,\n",
    "            n_iter=10,\n",
    "            scoring='r2',\n",
    "            random_state=42\n",
    "        )\n",
    "        best_params, best_score, best_estimator = knn_random_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['KNNRegressor'] =  {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        svr_model = SVRModel(loss_function=loss_fn)\n",
    "        svr_param_grid = {\n",
    "            'C': [0.1, 1.0],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "\n",
    "        svr_grid_optimizer = GridSearchOptimizer(\n",
    "            model_instance=svr_model,\n",
    "            param_grid=svr_param_grid,\n",
    "            loss_function=loss_fn,\n",
    "            cv=5,\n",
    "            scoring='r2'\n",
    "        )\n",
    "        best_params, best_score, best_estimator = svr_grid_optimizer.optimize(X_train, y_train)\n",
    "        val_score = best_estimator.score(X_val, y_val)\n",
    "\n",
    "        results_dict['SVRegressor'] = {\n",
    "            'model': best_estimator,\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score,\n",
    "            'validation_score': val_score\n",
    "        }\n",
    "\n",
    "        top_model_key, top_model_value = get_top_model(results_dict)\n",
    "        top_model = top_model_value['model']\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_filename = f\"best_model_{top_model_key}_{timestamp}.pkl\"\n",
    "        print(model_filename)\n",
    "        # Save the model using pickle\n",
    "        with open(model_filename, 'wb') as f:\n",
    "            pickle.dump(top_model, f)\n",
    "\n",
    "        print(f\"Top model {top_model_key} saved as {model_filename}\")\n",
    "\n",
    "        return top_model_key, top_model_value, results_dict\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown objective={objective}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Modeling Results Classification ---\n",
      "Before GridSearchCV: {'n_estimators': 100, 'max_depth': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After GridSearchCV: {'n_estimators': 250, 'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Before GridSearchCV: {'alpha': 1.0, 'binarize': 0.0, 'fit_prior': True}\n",
      "After GridSearchCV: {'alpha': 0.1, 'binarize': 1.0, 'fit_prior': True}\n",
      "Before GridSearchCV: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "After GridSearchCV: {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "Before GridSearchCV: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "After GridSearchCV: {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "Before GridSearchCV: {'max_iter': 200, 'penalty': 'l2', 'C': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/christopherpuglisi/anaconda3/envs/hyperparam/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After GridSearchCV: {'max_iter': 200, 'penalty': 'l2', 'C': 10.0, 'solver': 'liblinear'}\n",
      "best_model_LogisticClassifier_20250310_183120.pkl\n",
      "Top model LogisticClassifier saved as best_model_LogisticClassifier_20250310_183120.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Modeling Results Classification ---\")\n",
    "top_model_key, top_model_value, results_dict = run_model_experiment('Threat Detection Prediction', X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LogisticClassifier\n",
      "Details: {'model': LogisticModel(C=10.0, max_iter=200, penalty='l2', solver='liblinear'), 'best_params': {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}, 'best_score': 0.9805429864253394, 'validation_score': 0.9846153846153847}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Model: {top_model_key}\\nDetails: {top_model_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Modeling Results Regression ---\n",
      "Before GridSearchCV: {'max_iter': 200, 'penalty': 'l2', 'C': 1.0}\n",
      "After GridSearchCV: {'max_iter': 1000, 'penalty': None, 'C': 1.0}\n",
      "Before GridSearchCV: {'max_iter': 300, 'tol': 0.001, 'alpha_1': 1e-06, 'alpha_2': 1e-06, 'lambda_1': 1e-06, 'lambda_2': 1e-06}\n",
      "After GridSearchCV: {'max_iter': 100, 'tol': 0.001, 'alpha_1': 1e-06, 'alpha_2': 1e-05, 'lambda_1': 1e-06, 'lambda_2': 1e-06}\n",
      "Before GridSearchCV: {'alpha': 1.0}\n",
      "After GridSearchCV: {'alpha': 10.0}\n",
      "Before GridSearchCV: {'alpha': 1.0}\n",
      "After GridSearchCV: {'alpha': 0.01}\n",
      "Before GridSearchCV: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "After GridSearchCV: {'C': 1.0, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "best_model_LogisticRegression_20250310_183121.pkl\n",
      "Top model LogisticRegression saved as best_model_LogisticRegression_20250310_183121.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Modeling Results Regression ---\")\n",
    "all_results = run_model_experiment('Threat Severity Prediction', X_train, y_train, X_val, y_val, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_model_key, top_model_value = get_top_model(all_results)\n",
    "#print(f\"Best Model: {top_model_key}\\nDetails: {top_model_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized Loss Function:\n",
      "{\"name\": \"BinaryCrossEntropyLoss\", \"parameters\": {\"weight_fp\": 1, \"weight_fn\": 1, \"threshold\": 0.5}}\n"
     ]
    }
   ],
   "source": [
    "# Serialize the custom loss function to a JSON string\n",
    "serialized_loss = loss_fn.serialize()\n",
    "print(\"Serialized Loss Function:\")\n",
    "print(serialized_loss)\n",
    "\n",
    "# Optionally, save the serialized loss function to a file\n",
    "with open(serialized_loss_name, 'w') as f:\n",
    "    f.write(serialized_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deserialized Loss Function Parameters:\n",
      "{\n",
      "    \"weight_fp\": 1,\n",
      "    \"weight_fn\": 1,\n",
      "    \"threshold\": 0.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load the serialized loss function from the file\n",
    "with open(serialized_loss_name, 'r') as f:\n",
    "    loaded_serialized_loss = f.read()\n",
    "\n",
    "# Deserialize the loss function\n",
    "deserialized_loss_fn = LossFunctionFactory.deserialize_loss_function(loaded_serialized_loss)\n",
    "\n",
    "# Display deserialized loss function parameters\n",
    "print(\"Deserialized Loss Function Parameters:\")\n",
    "print(json.dumps(deserialized_loss_fn.parameters, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metadata saved to model_metadata_LogisticClassifier.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Function to generate model metadata automatically\n",
    "def generate_model_metadata(model_name, model_details, serialized_loss_name, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Generates structured metadata for the trained model automatically.\n",
    "    \"\"\"\n",
    "    # Load the serialized loss function\n",
    "    with open(serialized_loss_name, 'r') as f:\n",
    "        loaded_serialized_loss = f.read()\n",
    "\n",
    "    # Deserialize the loss function\n",
    "    deserialized_loss_fn = LossFunctionFactory.deserialize_loss_function(loaded_serialized_loss)\n",
    "\n",
    "    metadata = {\n",
    "        \"Model Identification and Versioning\": {\n",
    "            \"model_id\": f\"{model_name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "            \"name\": model_name,\n",
    "            \"version\": \"1.0\",  # Can be dynamically set based on retraining\n",
    "            \"creation_date\": str(datetime.datetime.now()),\n",
    "            \"model_lineage\": \"BaselineModel_v0.9\",  # If applicable, pull from model history\n",
    "            \"repo_link\": \"https://gitlab.com/path/to/models\",  # If stored in a repository\n",
    "            \"associated_reports\": [\"Report ##: Model deployment metadata\", \"Report ##: Model tracking\"]\n",
    "        },\n",
    "        \"Model Parameters and Architecture\": {\n",
    "            \"model_type\": model_details['model'].__class__.__name__,  # Extract model type\n",
    "            \"input_features\": list(X_train.columns),  # Features used in training\n",
    "            \"target_column\": \"Threat\",  # Adjust based on dataset label\n",
    "            \"loss_function\": serialized_loss_name,  # Reference to stored loss function\n",
    "            \"optimizer\": model_details['best_params'].get('solver', \"Unknown\"),  # Extract solver if exists\n",
    "            \"hyperparameters\": model_details['best_params']  # Full hyperparameter set\n",
    "        },\n",
    "        \"Training and Performance Metrics\": {\n",
    "            \"dataset_used\": {\n",
    "                \"train_samples\": X_train.shape[0],\n",
    "                \"val_samples\": X_val.shape[0],\n",
    "                \"feature_dim\": X_train.shape[1]\n",
    "            },\n",
    "            \"dataset_properties\": {\n",
    "                \"train_target_balance\": dict(y_train.value_counts().to_dict()),  # Auto-calculate class distribution\n",
    "                \"val_target_balance\": dict(y_val.value_counts().to_dict())  # Auto-calculate class distribution\n",
    "            },\n",
    "            \"performance_metrics\": {\n",
    "                \"best_score\": model_details['best_score'],  # Best score from model tuning\n",
    "                \"validation_score\": model_details['validation_score']  # Validation score\n",
    "            },\n",
    "            \"benchmark_metrics\": {\n",
    "                \"baseline_model_score\": 0.95  # If a benchmark exists, pull dynamically\n",
    "            },\n",
    "            \"uncertainty_quant\": {\n",
    "                \"weight_fp\": deserialized_loss_fn.parameters.get(\"weight_fp\", 1),\n",
    "                \"weight_fn\": deserialized_loss_fn.parameters.get(\"weight_fn\", 1),\n",
    "                \"threshold\": deserialized_loss_fn.parameters.get(\"threshold\", 0.5)\n",
    "            }\n",
    "        },\n",
    "        \"Threat Domain Information\": {\n",
    "            \"threat_type_modeled\": \"Biological Threat\",  # Can be parameterized\n",
    "            \"use_cases\": [\"Threat classification\", \"Anomaly detection\"],  # Example use cases\n",
    "            \"feature_explainability\": {\n",
    "                \"SHAP_analysis\": \"Pending\",  # Auto-compute if using SHAP later\n",
    "                \"Top_features\": [\"feature_1\", \"feature_2\"]  # Placeholder; should compute SHAP feature importances\n",
    "            },\n",
    "            \"compliance_metrics\": [\"Bias assessment: Passed\", \"Security audit: Passed\"]  # Example compliance checks\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Automatically generate metadata\n",
    "model_metadata = generate_model_metadata(top_model_key, top_model_value, serialized_loss_name, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Save metadata as JSON file\n",
    "metadata_filename = f\"model_metadata_{top_model_key}.json\"\n",
    "with open(metadata_filename, \"w\") as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "\n",
    "print(f\"Model metadata saved to {metadata_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model Identification and Versioning': {'model_id': 'LogisticClassifier_20250310_183121',\n",
       "  'name': 'LogisticClassifier',\n",
       "  'version': '1.0',\n",
       "  'creation_date': '2025-03-10 18:31:21.948939',\n",
       "  'model_lineage': 'BaselineModel_v0.9',\n",
       "  'repo_link': 'https://gitlab.com/path/to/models',\n",
       "  'associated_reports': ['Report ##: Model deployment metadata',\n",
       "   'Report ##: Model tracking']},\n",
       " 'Model Parameters and Architecture': {'model_type': 'LogisticModel',\n",
       "  'input_features': ['A1A5D9',\n",
       "   'A6NDG6',\n",
       "   'O00233',\n",
       "   'O00299',\n",
       "   'O00391',\n",
       "   'O00410',\n",
       "   'O00442',\n",
       "   'O00560',\n",
       "   'O00592',\n",
       "   'O00743',\n",
       "   'O14545',\n",
       "   'O14579',\n",
       "   'O14672',\n",
       "   'O14734',\n",
       "   'O14744',\n",
       "   'O14841',\n",
       "   'O14874',\n",
       "   'O14879',\n",
       "   'O14933',\n",
       "   'O14976',\n",
       "   'O14979',\n",
       "   'O15066',\n",
       "   'O15118',\n",
       "   'O15162',\n",
       "   'O15258',\n",
       "   'O15355',\n",
       "   'O15371',\n",
       "   'O15400',\n",
       "   'O15455',\n",
       "   'O43148',\n",
       "   'O43390',\n",
       "   'O43490',\n",
       "   'O43653',\n",
       "   'O43657',\n",
       "   'O43678',\n",
       "   'O43747',\n",
       "   'O43768',\n",
       "   'O43809',\n",
       "   'O43823',\n",
       "   'O43837',\n",
       "   'O43865',\n",
       "   'O43920',\n",
       "   'O60220',\n",
       "   'O60237',\n",
       "   'O60256',\n",
       "   'O60513',\n",
       "   'O60701',\n",
       "   'O60783',\n",
       "   'O60784',\n",
       "   'O60828',\n",
       "   'O75131',\n",
       "   'O75380',\n",
       "   'O76062',\n",
       "   'O94903',\n",
       "   'O94905',\n",
       "   'O94913',\n",
       "   'O95373',\n",
       "   'O95433',\n",
       "   'O95436',\n",
       "   'O95573',\n",
       "   'O95721',\n",
       "   'O95786',\n",
       "   'O95831',\n",
       "   'O95834',\n",
       "   'O95857',\n",
       "   'P00167',\n",
       "   'P00450',\n",
       "   'P00558',\n",
       "   'P00973',\n",
       "   'P01024',\n",
       "   'P01033',\n",
       "   'P01034',\n",
       "   'P01833',\n",
       "   'P02686',\n",
       "   'P03928',\n",
       "   'P03973',\n",
       "   'P04075',\n",
       "   'P04424',\n",
       "   'P04843',\n",
       "   'P05141',\n",
       "   'P05161',\n",
       "   'P06132',\n",
       "   'P07602',\n",
       "   'P07814',\n",
       "   'P07902',\n",
       "   'P08134',\n",
       "   'P08397',\n",
       "   'P08621',\n",
       "   'P08754',\n",
       "   'P09110',\n",
       "   'P09661',\n",
       "   'P10155',\n",
       "   'P10606',\n",
       "   'P10620',\n",
       "   'P10768',\n",
       "   'P11142',\n",
       "   'P11279',\n",
       "   'P11766',\n",
       "   'P11908',\n",
       "   'P12270',\n",
       "   'P12931',\n",
       "   'P13489',\n",
       "   'P13726',\n",
       "   'P13798',\n",
       "   'P13987',\n",
       "   'P14550',\n",
       "   'P14866',\n",
       "   'P14868',\n",
       "   'P14902',\n",
       "   'P15104',\n",
       "   'P15170',\n",
       "   'P15291',\n",
       "   'P15328',\n",
       "   'P15907',\n",
       "   'P15941',\n",
       "   'P16220',\n",
       "   'P16455',\n",
       "   'P17152',\n",
       "   'P17301',\n",
       "   'P17655',\n",
       "   'P17900',\n",
       "   'P17936',\n",
       "   'P17987',\n",
       "   'P18206',\n",
       "   'P18754',\n",
       "   'P19387',\n",
       "   'P19404',\n",
       "   'P20061',\n",
       "   'P20073',\n",
       "   'P20591',\n",
       "   'P21127',\n",
       "   'P21953',\n",
       "   'P22059',\n",
       "   'P22307',\n",
       "   'P22314',\n",
       "   'P23246',\n",
       "   'P23258',\n",
       "   'P23368',\n",
       "   'P23497',\n",
       "   'P23588',\n",
       "   'P25398',\n",
       "   'P25445',\n",
       "   'P26583',\n",
       "   'P26885',\n",
       "   'P27144',\n",
       "   'P27695',\n",
       "   'P27824',\n",
       "   'P29350',\n",
       "   'P29728',\n",
       "   'P30040',\n",
       "   'P30086',\n",
       "   'P30153',\n",
       "   'P30520',\n",
       "   'P31483',\n",
       "   'P31939',\n",
       "   'P34913',\n",
       "   'P34949',\n",
       "   'P35249',\n",
       "   'P35269',\n",
       "   'P35637',\n",
       "   'P35813',\n",
       "   'P36969',\n",
       "   'P37268',\n",
       "   'P39019',\n",
       "   'P39023',\n",
       "   'P41212',\n",
       "   'P42224',\n",
       "   'P46060',\n",
       "   'P46776',\n",
       "   'P48163',\n",
       "   'P48506',\n",
       "   'P49321',\n",
       "   'P49406',\n",
       "   'P49459',\n",
       "   'P49585',\n",
       "   'P49750',\n",
       "   'P49756',\n",
       "   'P49790',\n",
       "   'P49821',\n",
       "   'P49916',\n",
       "   'P50225',\n",
       "   'P51149',\n",
       "   'P52630',\n",
       "   'P52756',\n",
       "   'P52815',\n",
       "   'P52895',\n",
       "   'P53007',\n",
       "   'P53621',\n",
       "   'P53992',\n",
       "   'P54136',\n",
       "   'P55060',\n",
       "   'P55081',\n",
       "   'P55265',\n",
       "   'P55735',\n",
       "   'P55769',\n",
       "   'P56181',\n",
       "   'P56385',\n",
       "   'P57737',\n",
       "   'P60174',\n",
       "   'P60900',\n",
       "   'P61026',\n",
       "   'P61158',\n",
       "   'P61160',\n",
       "   'P61457',\n",
       "   'P61586',\n",
       "   'P61604',\n",
       "   'P62070',\n",
       "   'P62081',\n",
       "   'P62136',\n",
       "   'P62191',\n",
       "   'P62269',\n",
       "   'P62273',\n",
       "   'P62280',\n",
       "   'P62310',\n",
       "   'P62834',\n",
       "   'P62861',\n",
       "   'P62875',\n",
       "   'P62879',\n",
       "   'P62888',\n",
       "   'P62899',\n",
       "   'P62906',\n",
       "   'P62910',\n",
       "   'P62995',\n",
       "   'P63244',\n",
       "   'P63279',\n",
       "   'P67775',\n",
       "   'P67870',\n",
       "   'P68366',\n",
       "   'P68371',\n",
       "   'P78318',\n",
       "   'P78371',\n",
       "   'P78406',\n",
       "   'P78527',\n",
       "   'P80188',\n",
       "   'P80217',\n",
       "   'P82650',\n",
       "   'P82664',\n",
       "   'P82912',\n",
       "   'P82932',\n",
       "   'P82979',\n",
       "   'P84095',\n",
       "   'P84098',\n",
       "   'P98175',\n",
       "   'Q00059',\n",
       "   'Q00341',\n",
       "   'Q00610',\n",
       "   'Q00978',\n",
       "   'Q01844',\n",
       "   'Q02543',\n",
       "   'Q02878',\n",
       "   'Q04323',\n",
       "   'Q04941',\n",
       "   'Q05048',\n",
       "   'Q05519',\n",
       "   'Q06136',\n",
       "   'Q06210',\n",
       "   'Q06787',\n",
       "   'Q07617',\n",
       "   'Q07955',\n",
       "   'Q08380',\n",
       "   'Q12873',\n",
       "   'Q12906',\n",
       "   'Q12907',\n",
       "   'Q12972',\n",
       "   'Q12996',\n",
       "   'Q13098',\n",
       "   'Q13151',\n",
       "   'Q13155',\n",
       "   'Q13188',\n",
       "   'Q13247',\n",
       "   'Q13283',\n",
       "   'Q13287',\n",
       "   'Q13421',\n",
       "   'Q13442',\n",
       "   'Q13443',\n",
       "   'Q13561',\n",
       "   'Q13564',\n",
       "   'Q13573',\n",
       "   'Q13576',\n",
       "   'Q14011',\n",
       "   'Q14108',\n",
       "   'Q14157',\n",
       "   'Q14203',\n",
       "   'Q14244',\n",
       "   'Q14498',\n",
       "   'Q14508',\n",
       "   'Q14694',\n",
       "   'Q14997',\n",
       "   'Q15007',\n",
       "   'Q15020',\n",
       "   'Q15046',\n",
       "   'Q15050',\n",
       "   'Q15059',\n",
       "   'Q15365',\n",
       "   'Q15369',\n",
       "   'Q15417',\n",
       "   'Q15437',\n",
       "   'Q15637',\n",
       "   'Q16348',\n",
       "   'Q16543',\n",
       "   'Q16563',\n",
       "   'Q16576',\n",
       "   'Q16629',\n",
       "   'Q16850',\n",
       "   'Q3LXA3',\n",
       "   'Q460N5',\n",
       "   'Q4VC31',\n",
       "   'Q53GD3',\n",
       "   'Q56VL3',\n",
       "   'Q5EBM0',\n",
       "   'Q5HYI8',\n",
       "   'Q5QJ74',\n",
       "   'Q5RKV6',\n",
       "   'Q5SXH7',\n",
       "   'Q5T1M5',\n",
       "   'Q5T4S7',\n",
       "   'Q5T5P2',\n",
       "   'Q5T6V5',\n",
       "   'Q5XKP0',\n",
       "   'Q6NW29',\n",
       "   'Q6P161',\n",
       "   'Q6P1N9',\n",
       "   'Q6P1X6',\n",
       "   'Q6P2E9',\n",
       "   'Q6UN15',\n",
       "   'Q7L5L3',\n",
       "   'Q7L5N1',\n",
       "   'Q7L5Y1',\n",
       "   'Q7Z4Q2',\n",
       "   'Q7Z4V5',\n",
       "   'Q7Z7K0',\n",
       "   'Q86SF2',\n",
       "   'Q86VP6',\n",
       "   'Q86X55',\n",
       "   'Q86XP3',\n",
       "   'Q8IU81',\n",
       "   'Q8IVF2',\n",
       "   'Q8IVT2',\n",
       "   'Q8IWX8',\n",
       "   'Q8IXM3',\n",
       "   'Q8IXQ6',\n",
       "   'Q8IXT5',\n",
       "   'Q8IYB3',\n",
       "   'Q8IYJ3',\n",
       "   'Q8IZL8',\n",
       "   'Q8IZV5',\n",
       "   'Q8N183',\n",
       "   'Q8N3Y7',\n",
       "   'Q8N684',\n",
       "   'Q8N8R3',\n",
       "   'Q8NBJ7',\n",
       "   'Q8NC56',\n",
       "   'Q8NEU8',\n",
       "   'Q8NFJ5',\n",
       "   'Q8NFW8',\n",
       "   'Q8NFZ8',\n",
       "   'Q8NI22',\n",
       "   'Q8TAE8',\n",
       "   'Q8TBC4',\n",
       "   'Q8TDB6',\n",
       "   'Q8TDL5',\n",
       "   'Q8WU90',\n",
       "   'Q8WUD4',\n",
       "   'Q8WVC0',\n",
       "   'Q8WW22',\n",
       "   'Q8WWM7',\n",
       "   'Q8WXI7',\n",
       "   'Q8WXX5',\n",
       "   'Q92520',\n",
       "   'Q92541',\n",
       "   'Q92575',\n",
       "   'Q92598',\n",
       "   'Q92688',\n",
       "   'Q92696',\n",
       "   'Q92805',\n",
       "   'Q92841',\n",
       "   'Q92879',\n",
       "   'Q92896',\n",
       "   'Q92911',\n",
       "   'Q93008',\n",
       "   'Q93052',\n",
       "   'Q969G3',\n",
       "   'Q96BM9',\n",
       "   'Q96BP2',\n",
       "   'Q96C36',\n",
       "   'Q96CW1',\n",
       "   'Q96D53',\n",
       "   'Q96HE7',\n",
       "   'Q96I24',\n",
       "   'Q96IZ0',\n",
       "   'Q96MU7',\n",
       "   'Q96N66',\n",
       "   'Q96NY8',\n",
       "   'Q96Q11',\n",
       "   'Q96RN5',\n",
       "   'Q96T37',\n",
       "   'Q96TA2',\n",
       "   'Q99102',\n",
       "   'Q99538',\n",
       "   'Q99615',\n",
       "   'Q99627',\n",
       "   'Q99700',\n",
       "   'Q99714',\n",
       "   'Q99733',\n",
       "   'Q99747',\n",
       "   'Q99805',\n",
       "   'Q99816',\n",
       "   'Q99828',\n",
       "   'Q9BQB6',\n",
       "   'Q9BQC6',\n",
       "   'Q9BQS8',\n",
       "   'Q9BR76',\n",
       "   'Q9BRJ2',\n",
       "   'Q9BRT3',\n",
       "   'Q9BTE6',\n",
       "   'Q9BUL8',\n",
       "   'Q9BVK6',\n",
       "   'Q9BW83',\n",
       "   'Q9BW91',\n",
       "   'Q9BY32',\n",
       "   'Q9BY77',\n",
       "   'Q9BYD2',\n",
       "   'Q9BYK8',\n",
       "   'Q9BZL6',\n",
       "   'Q9GZT3',\n",
       "   'Q9H098',\n",
       "   'Q9H0P0',\n",
       "   'Q9H2K0',\n",
       "   'Q9H2P0',\n",
       "   'Q9H307',\n",
       "   'Q9H3Q1',\n",
       "   'Q9H488',\n",
       "   'Q9H4A4',\n",
       "   'Q9H5N1',\n",
       "   'Q9H5V8',\n",
       "   'Q9H6S3',\n",
       "   'Q9H832',\n",
       "   'Q9H8W4',\n",
       "   'Q9H8Y5',\n",
       "   'Q9HCU5',\n",
       "   'Q9HD20',\n",
       "   'Q9HD33',\n",
       "   'Q9HD34',\n",
       "   'Q9HD45',\n",
       "   'Q9NP55',\n",
       "   'Q9NP66',\n",
       "   'Q9NP72',\n",
       "   'Q9NP74',\n",
       "   'Q9NPJ6',\n",
       "   'Q9NQ48',\n",
       "   'Q9NQ84',\n",
       "   'Q9NQR4',\n",
       "   'Q9NR46',\n",
       "   'Q9NRX4',\n",
       "   'Q9NS86',\n",
       "   'Q9NV96',\n",
       "   'Q9NW64',\n",
       "   'Q9NWH9',\n",
       "   'Q9NY12',\n",
       "   'Q9NYF8',\n",
       "   'Q9P015',\n",
       "   'Q9P206',\n",
       "   'Q9P258',\n",
       "   'Q9P2M7',\n",
       "   'Q9UBQ0',\n",
       "   'Q9UEE9',\n",
       "   'Q9UGP4',\n",
       "   'Q9UI30',\n",
       "   'Q9UIA9',\n",
       "   'Q9UJC3',\n",
       "   'Q9UJY5',\n",
       "   'Q9UK45',\n",
       "   'Q9UKL0',\n",
       "   'Q9UKR5',\n",
       "   'Q9UKV3',\n",
       "   'Q9UL25',\n",
       "   'Q9ULV0',\n",
       "   'Q9UMX5',\n",
       "   'Q9UNE7',\n",
       "   'Q9UNM6',\n",
       "   'Q9UNS2',\n",
       "   'Q9UPN6',\n",
       "   'Q9UPT8',\n",
       "   'Q9UPY8',\n",
       "   'Q9UQ35',\n",
       "   'Q9UQB8',\n",
       "   'Q9Y230',\n",
       "   'Q9Y237',\n",
       "   'Q9Y265',\n",
       "   'Q9Y266',\n",
       "   'Q9Y3A3',\n",
       "   'Q9Y3B3',\n",
       "   'Q9Y3B9',\n",
       "   'Q9Y3D9',\n",
       "   'Q9Y3S1',\n",
       "   'Q9Y4X5',\n",
       "   'Q9Y5P6',\n",
       "   'Q9Y5Y6',\n",
       "   'Q9Y678',\n",
       "   'Q9Y6C9',\n",
       "   'Q9Y6D6',\n",
       "   'Q9Y6I3',\n",
       "   'Q9Y6K5',\n",
       "   'Q9Y6M7',\n",
       "   'A0AV96',\n",
       "   'O14776',\n",
       "   'O43286',\n",
       "   'O43520',\n",
       "   'O75376',\n",
       "   'O94832',\n",
       "   'O94979',\n",
       "   'P04406',\n",
       "   'P07900',\n",
       "   'P07919',\n",
       "   'P08238',\n",
       "   'P09543',\n",
       "   'P09914',\n",
       "   'Q5T764',\n",
       "   'P0DN76',\n",
       "   'Q01081',\n",
       "   'P0DP25',\n",
       "   'P0DP24',\n",
       "   'P0DP23',\n",
       "   'P13688',\n",
       "   'P31997',\n",
       "   'P13693',\n",
       "   'Q9HAU6',\n",
       "   'Q56UQ5',\n",
       "   'P21217',\n",
       "   'Q11128',\n",
       "   'P27635',\n",
       "   'Q96L21',\n",
       "   'P38159',\n",
       "   'P41091',\n",
       "   'Q2VIR3',\n",
       "   'P52298',\n",
       "   'P52655',\n",
       "   'P60953',\n",
       "   'P62328',\n",
       "   'P62750',\n",
       "   'P63000',\n",
       "   'P60763',\n",
       "   'P63165',\n",
       "   'G2XKQ0',\n",
       "   'P68104',\n",
       "   'Q5VTE0',\n",
       "   'Q02218',\n",
       "   'Q08AF3',\n",
       "   'Q13310',\n",
       "   'Q13409',\n",
       "   'Q15366',\n",
       "   'Q15717',\n",
       "   'Q4V328',\n",
       "   'Q8N392',\n",
       "   'Q96CX2',\n",
       "   'Q96JP5',\n",
       "   'Q9BW30',\n",
       "   'Q9ULH7',\n",
       "   'Q9Y4E1',\n",
       "   'Q9Y6H1',\n",
       "   'Q5T1J5'],\n",
       "  'target_column': 'Threat',\n",
       "  'loss_function': 'binary_cross_entropy_loss.json',\n",
       "  'optimizer': 'liblinear',\n",
       "  'hyperparameters': {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}},\n",
       " 'Training and Performance Metrics': {'dataset_used': {'train_samples': 258,\n",
       "   'val_samples': 65,\n",
       "   'feature_dim': 561},\n",
       "  'dataset_properties': {'train_target_balance': {1: 187, 0: 71},\n",
       "   'val_target_balance': {1: 47, 0: 18}},\n",
       "  'performance_metrics': {'best_score': 0.9805429864253394,\n",
       "   'validation_score': 0.9846153846153847},\n",
       "  'benchmark_metrics': {'baseline_model_score': 0.95},\n",
       "  'uncertainty_quant': {'weight_fp': 1, 'weight_fn': 1, 'threshold': 0.5}},\n",
       " 'Threat Domain Information': {'threat_type_modeled': 'Biological Threat',\n",
       "  'use_cases': ['Threat classification', 'Anomaly detection'],\n",
       "  'feature_explainability': {'SHAP_analysis': 'Pending',\n",
       "   'Top_features': ['feature_1', 'feature_2']},\n",
       "  'compliance_metrics': ['Bias assessment: Passed', 'Security audit: Passed']}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    elif objective_type == 'Detect Latent Patterns':\n",
    "        model_type = 'KMeans'\n",
    "        if model_type == 'KMeans':\n",
    "            km_model = KMeansModel(loss_function=loss_fn)\n",
    "            km_param_grid = {\n",
    "                'n_clusters': [2, 3, 5, 8],\n",
    "                'init': ['k-means++', 'random'],\n",
    "                'max_iter': [100, 300],\n",
    "            }\n",
    "\n",
    "            km_grid_optimizer = GridSearchOptimizer(\n",
    "                model_instance=km_model,\n",
    "                param_grid=km_param_grid,\n",
    "                loss_function=loss_fn,  \n",
    "                cv=None,\n",
    "                scoring=None\n",
    "            )\n",
    "            # We assume 3 values returned:\n",
    "            best_params, best_score, best_estimator = km_grid_optimizer.optimize(X_train, None)\n",
    "            val_score = best_estimator.score(X_val, None)\n",
    "\n",
    "            return {\n",
    "                'model': best_estimator,\n",
    "                'best_params': best_params,\n",
    "                'best_score': best_score,\n",
    "                'validation_score': val_score\n",
    "            }\n",
    "\n",
    "        elif model_type == 'DBSCAN':\n",
    "            dbscan_model = DBSCANModel(loss_function=loss_fn)\n",
    "            dbscan_param_distributions = {\n",
    "                'eps': [0.1, 0.2, 0.5, 1.0],\n",
    "                'min_samples': [3, 5, 10]\n",
    "            }\n",
    "\n",
    "            dbscan_random_optimizer = RandomSearchOptimizer(\n",
    "                model_instance=dbscan_model,\n",
    "                param_distributions=dbscan_param_distributions,\n",
    "                loss_function=loss_fn,\n",
    "                n_iter=5,\n",
    "                scoring=None,\n",
    "                random_state=42\n",
    "            )\n",
    "            best_params, best_score, best_estimator = dbscan_random_optimizer.optimize(X_train, None)\n",
    "            val_score = best_estimator.score(X_val, None)\n",
    "\n",
    "            return {\n",
    "                'model': best_estimator,\n",
    "                'best_params': best_params,\n",
    "                'best_score': best_score,\n",
    "                'validation_score': val_score\n",
    "            }\n",
    "\n",
    "        elif model_type == 'AgglomerativeClustering':\n",
    "            agg_model = AgglomerativeClusteringModel(loss_function=loss_fn)\n",
    "            agg_param_grid = {\n",
    "                'n_clusters': [2, 3, 5, 8],\n",
    "                'affinity': ['euclidean', 'manhattan'],\n",
    "                'linkage': ['ward', 'complete', 'average']\n",
    "            }\n",
    "\n",
    "            agg_grid_optimizer = GridSearchOptimizer(\n",
    "                model_instance=agg_model,\n",
    "                param_grid=agg_param_grid,\n",
    "                loss_function=loss_fn,\n",
    "                cv=None,\n",
    "                scoring=None\n",
    "            )\n",
    "            best_params, best_score, best_estimator = agg_grid_optimizer.optimize(X_train, None)\n",
    "            val_score = best_estimator.score(X_val, None)\n",
    "\n",
    "            return {\n",
    "                'model': best_estimator,\n",
    "                'best_params': best_params,\n",
    "                'best_score': best_score,\n",
    "                'validation_score': val_score\n",
    "            }\n",
    "\n",
    "        elif model_type == 'SpectralClustering':\n",
    "            spectral_model = SpectralClusteringModel(loss_function=loss_fn)\n",
    "            spectral_param_grid = {\n",
    "                'n_clusters': [2, 3, 5, 8],\n",
    "                'n_init': [5, 10],\n",
    "                'gamma': [0.1, 1.0, 10.0]\n",
    "            }\n",
    "\n",
    "            spectral_grid_optimizer = GridSearchOptimizer(\n",
    "                model_instance=spectral_model,\n",
    "                param_grid=spectral_param_grid,\n",
    "                loss_function=loss_fn,\n",
    "                cv=None,\n",
    "                scoring=None\n",
    "            )\n",
    "            best_params, best_score, best_estimator = spectral_grid_optimizer.optimize(X_train, None)\n",
    "            val_score = best_estimator.score(X_val, None)\n",
    "\n",
    "            return {\n",
    "                'model': best_estimator,\n",
    "                'best_params': best_params,\n",
    "                'best_score': best_score,\n",
    "                'validation_score': val_score\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown unsupervised model_type={model_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
